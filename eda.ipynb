{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac582cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n",
      "Found 6043 images belonging to 2 classes.\n",
      "Found 1510 images belonging to 2 classes.\n",
      "\n",
      "Class indices (IMPORTANT - record this for your Streamlit app!): {'with_mask': 0, 'without_mask': 1}\n",
      "\n",
      "--- Training Phase 1: Head Only ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\24ksh\\OneDrive\\Desktop\\mask detec2\\venv\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m 58/189\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 902ms/step - accuracy: 0.6941 - loss: 0.7189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\24ksh\\OneDrive\\Desktop\\mask detec2\\venv\\lib\\site-packages\\PIL\\Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904ms/step - accuracy: 0.8248 - loss: 0.4219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\24ksh\\OneDrive\\Desktop\\mask detec2\\venv\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.97616, saving model to mask_classifier_phase1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 1s/step - accuracy: 0.8252 - loss: 0.4208 - val_accuracy: 0.9762 - val_loss: 0.0789\n",
      "Epoch 2/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611ms/step - accuracy: 0.9655 - loss: 0.0862\n",
      "Epoch 2: val_accuracy improved from 0.97616 to 0.98079, saving model to mask_classifier_phase1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 766ms/step - accuracy: 0.9655 - loss: 0.0861 - val_accuracy: 0.9808 - val_loss: 0.0505\n",
      "Epoch 3/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633ms/step - accuracy: 0.9747 - loss: 0.0641\n",
      "Epoch 3: val_accuracy improved from 0.98079 to 0.98278, saving model to mask_classifier_phase1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 795ms/step - accuracy: 0.9747 - loss: 0.0641 - val_accuracy: 0.9828 - val_loss: 0.0458\n",
      "Epoch 4/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646ms/step - accuracy: 0.9777 - loss: 0.0595\n",
      "Epoch 4: val_accuracy improved from 0.98278 to 0.98344, saving model to mask_classifier_phase1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 797ms/step - accuracy: 0.9777 - loss: 0.0595 - val_accuracy: 0.9834 - val_loss: 0.0453\n",
      "Epoch 5/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616ms/step - accuracy: 0.9771 - loss: 0.0618\n",
      "Epoch 5: val_accuracy did not improve from 0.98344\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 767ms/step - accuracy: 0.9771 - loss: 0.0618 - val_accuracy: 0.9795 - val_loss: 0.0599\n",
      "Epoch 6/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step - accuracy: 0.9825 - loss: 0.0479\n",
      "Epoch 6: val_accuracy did not improve from 0.98344\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 764ms/step - accuracy: 0.9825 - loss: 0.0479 - val_accuracy: 0.9801 - val_loss: 0.0446\n",
      "Epoch 7/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624ms/step - accuracy: 0.9869 - loss: 0.0404\n",
      "Epoch 7: val_accuracy did not improve from 0.98344\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 785ms/step - accuracy: 0.9869 - loss: 0.0404 - val_accuracy: 0.9821 - val_loss: 0.0487\n",
      "Epoch 8/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - accuracy: 0.9825 - loss: 0.0465\n",
      "Epoch 8: val_accuracy improved from 0.98344 to 0.98477, saving model to mask_classifier_phase1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 753ms/step - accuracy: 0.9825 - loss: 0.0465 - val_accuracy: 0.9848 - val_loss: 0.0458\n",
      "Epoch 9/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - accuracy: 0.9857 - loss: 0.0434\n",
      "Epoch 9: val_accuracy improved from 0.98477 to 0.98742, saving model to mask_classifier_phase1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 704ms/step - accuracy: 0.9857 - loss: 0.0434 - val_accuracy: 0.9874 - val_loss: 0.0342\n",
      "Epoch 10/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567ms/step - accuracy: 0.9827 - loss: 0.0521\n",
      "Epoch 10: val_accuracy did not improve from 0.98742\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 705ms/step - accuracy: 0.9827 - loss: 0.0521 - val_accuracy: 0.9874 - val_loss: 0.0480\n",
      "Epoch 11/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - accuracy: 0.9843 - loss: 0.0452\n",
      "Epoch 11: val_accuracy did not improve from 0.98742\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 722ms/step - accuracy: 0.9842 - loss: 0.0452 - val_accuracy: 0.9848 - val_loss: 0.0456\n",
      "Epoch 12/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567ms/step - accuracy: 0.9792 - loss: 0.0510\n",
      "Epoch 12: val_accuracy did not improve from 0.98742\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 708ms/step - accuracy: 0.9792 - loss: 0.0510 - val_accuracy: 0.9841 - val_loss: 0.0511\n",
      "Epoch 13/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.9821 - loss: 0.0452\n",
      "Epoch 13: val_accuracy did not improve from 0.98742\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 731ms/step - accuracy: 0.9821 - loss: 0.0452 - val_accuracy: 0.9848 - val_loss: 0.0498\n",
      "Epoch 14/15\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619ms/step - accuracy: 0.9821 - loss: 0.0517\n",
      "Epoch 14: val_accuracy improved from 0.98742 to 0.98808, saving model to mask_classifier_phase1_best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 769ms/step - accuracy: 0.9821 - loss: 0.0517 - val_accuracy: 0.9881 - val_loss: 0.0474\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Phase 2: Full Fine-tuning ---\n",
      "Epoch 1/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.9841 - loss: 0.0471\n",
      "Epoch 1: val_accuracy improved from -inf to 0.98808, saving model to mask_detector_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 735ms/step - accuracy: 0.9841 - loss: 0.0471 - val_accuracy: 0.9881 - val_loss: 0.0384 - learning_rate: 1.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - accuracy: 0.9833 - loss: 0.0471\n",
      "Epoch 2: val_accuracy did not improve from 0.98808\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 708ms/step - accuracy: 0.9833 - loss: 0.0471 - val_accuracy: 0.9854 - val_loss: 0.0521 - learning_rate: 1.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9818 - loss: 0.0522\n",
      "Epoch 3: val_accuracy did not improve from 0.98808\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 704ms/step - accuracy: 0.9818 - loss: 0.0522 - val_accuracy: 0.9874 - val_loss: 0.0520 - learning_rate: 1.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612ms/step - accuracy: 0.9852 - loss: 0.0430\n",
      "Epoch 4: val_accuracy did not improve from 0.98808\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 762ms/step - accuracy: 0.9852 - loss: 0.0431 - val_accuracy: 0.9834 - val_loss: 0.0393 - learning_rate: 1.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617ms/step - accuracy: 0.9827 - loss: 0.0464\n",
      "Epoch 5: val_accuracy did not improve from 0.98808\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 818ms/step - accuracy: 0.9827 - loss: 0.0464 - val_accuracy: 0.9854 - val_loss: 0.0462 - learning_rate: 2.0000e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885ms/step - accuracy: 0.9837 - loss: 0.0514\n",
      "Epoch 6: val_accuracy did not improve from 0.98808\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 1s/step - accuracy: 0.9837 - loss: 0.0514 - val_accuracy: 0.9868 - val_loss: 0.0409 - learning_rate: 2.0000e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - accuracy: 0.9827 - loss: 0.0468\n",
      "Epoch 7: val_accuracy did not improve from 0.98808\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 715ms/step - accuracy: 0.9827 - loss: 0.0468 - val_accuracy: 0.9848 - val_loss: 0.0558 - learning_rate: 2.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9836 - loss: 0.0450\n",
      "Epoch 8: val_accuracy did not improve from 0.98808\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 732ms/step - accuracy: 0.9836 - loss: 0.0450 - val_accuracy: 0.9874 - val_loss: 0.0470 - learning_rate: 4.0000e-07\n",
      "Epoch 9/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step - accuracy: 0.9828 - loss: 0.0496\n",
      "Epoch 9: val_accuracy did not improve from 0.98808\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 856ms/step - accuracy: 0.9828 - loss: 0.0495 - val_accuracy: 0.9821 - val_loss: 0.0479 - learning_rate: 4.0000e-07\n",
      "Epoch 10/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - accuracy: 0.9798 - loss: 0.0480\n",
      "Epoch 10: val_accuracy did not improve from 0.98808\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 823ms/step - accuracy: 0.9798 - loss: 0.0479 - val_accuracy: 0.9874 - val_loss: 0.0395 - learning_rate: 4.0000e-07\n",
      "Epoch 11/50\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677ms/step - accuracy: 0.9858 - loss: 0.0389\n",
      "Epoch 11: val_accuracy did not improve from 0.98808\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 841ms/step - accuracy: 0.9858 - loss: 0.0390 - val_accuracy: 0.9828 - val_loss: 0.0526 - learning_rate: 1.0000e-07\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Mask classifier training complete. Best model saved as 'mask_detector_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# train_mask_classifier.py\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "# --- Configuration ---\n",
    "data_dir = \"data\"  # Directory containing 'with_mask' and 'without_mask' subfolders\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "num_classes = 2 # 'with_mask' and 'without_mask'\n",
    "\n",
    "# --- 1. Data Generators ---\n",
    "# Now, the ImageDataGenerator will split the 'data' directory directly into\n",
    "# training and validation sets based on the validation_split.\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    validation_split=0.2, #20% of images for validation\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=data_dir, # Point directly to the 'data' folder\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\", # Specify this for the training set\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    directory=data_dir, # Point directly to the 'data' folder again\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\", # Specify this for the validation set\n",
    "    shuffle=False # Keep validation order consistent\n",
    ")\n",
    "\n",
    "# --- CRITICAL: Print Class Indices ---\n",
    "# This output tells you the exact mapping of class names to integer labels (0, 1)\n",
    "print(\"\\nClass indices (IMPORTANT - record this for your Streamlit app!):\", train_generator.class_indices)\n",
    "# Expected output based on your folder structure ('with_mask', 'without_mask'):\n",
    "# {'with_mask': 0, 'without_mask': 1}\n",
    "\n",
    "# --- 2. Build MobileNetV2 Model ---\n",
    "base_model = MobileNetV2(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Phase 1: Freeze base model and train the head (new classification layers)\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = Input(shape=(img_size, img_size, 3))\n",
    "x = base_model(inputs, training=False) # Important: set training=False when base_model is frozen\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x) # Add dropout for regularization\n",
    "outputs = Dense(num_classes, activation='softmax')(x) # Softmax for 2 classes\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# --- 3. Compile and Train Phase 1 (Head Only) ---\n",
    "print(\"\\n--- Training Phase 1: Head Only ---\")\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3), # Relatively higher learning rate for the new head\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks_phase1 = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='mask_classifier_phase1_best.h5', # Save the best model from this phase\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', # Stop if validation loss doesn't improve\n",
    "        patience=5, # Number of epochs to wait\n",
    "        restore_best_weights=True, # Load best weights found\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=15, # Initial epochs for head training\n",
    "    callbacks=callbacks_phase1\n",
    ")\n",
    "\n",
    "# Load the best model from Phase 1 to ensure we continue fine-tuning from the best weights\n",
    "model = tf.keras.models.load_model('mask_classifier_phase1_best.h5')\n",
    "\n",
    "# --- 4. Compile and Train Phase 2 (Full Fine-tuning) ---\n",
    "print(\"\\n--- Training Phase 2: Full Fine-tuning ---\")\n",
    "\n",
    "# Unfreeze base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "\n",
    "# Recompile with a very low learning rate for fine-tuning\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5), # CRITICAL: Very small learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks_phase2 = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='mask_detector_model.h5', # This will be your final model saved\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10, # More patience for fine-tuning\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau( # Reduce learning rate if validation loss plateaus\n",
    "        monitor='val_loss',\n",
    "        factor=0.2, # Reduce LR by factor of 0.2\n",
    "        patience=3, # If val_loss doesn't improve for 3 epochs\n",
    "        min_lr=1e-7, # Don't let LR go below this\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50, # More epochs for fine-tuning\n",
    "    callbacks=callbacks_phase2\n",
    ")\n",
    "\n",
    "print(\"\\nMask classifier training complete. Best model saved as 'mask_detector_model.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96812d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
